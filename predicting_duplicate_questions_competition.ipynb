{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Duplicate Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for this analysis is to accuractely predict if pairs of questions have the same meaning or not. This work is for the Kaggle Competition - \"Quora Question Pairs\": https://www.kaggle.com/c/quora-question-pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, time, json\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, \\\n",
    "                         Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n",
      "(2345796, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       0\n",
      "question2       2\n",
      "is_duplicate    0\n",
      "dtype: int64\n",
      "test_id      0\n",
      "question1    2\n",
      "question2    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for any null values\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the string 'empty' to empty strings\n",
    "train = train.fillna('empty')\n",
    "test = test.fillna('empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       0\n",
      "question2       0\n",
      "is_duplicate    0\n",
      "dtype: int64\n",
      "test_id      0\n",
      "question1    0\n",
      "question2    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "What is the step by step guide to invest in share market?\n",
      "\n",
      "What is the story of Kohinoor (Koh-i-Noor) Diamond?\n",
      "What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\n",
      "\n",
      "How can I increase the speed of my internet connection while using a VPN?\n",
      "How can Internet speed be increased by hacking through DNS?\n",
      "\n",
      "Why am I mentally very lonely? How can I solve it?\n",
      "Find the remainder when [math]23^{24}[/math] is divided by 24,23?\n",
      "\n",
      "Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?\n",
      "Which fish would survive in salt water?\n",
      "\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview some of the pairs of questions\n",
    "for i in range(6):\n",
    "    print(train.question1[i])\n",
    "    print(train.question2[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\":\", \" \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\"usa\", \"America\", text)\n",
    "    text = re.sub(r\"canada\", \"Canada\", text)\n",
    "    text = re.sub(r\"japan\", \"Japan\", text)\n",
    "    text = re.sub(r\"germany\", \"Germany\", text)\n",
    "    text = re.sub(r\"burma\", \"Burma\", text)\n",
    "    text = re.sub(r\"rohingya\", \"Rohingya\", text)\n",
    "    text = re.sub(r\"zealand\", \"Zealand\", text)\n",
    "    text = re.sub(r\"cambodia\", \"Cambodia\", text)\n",
    "    text = re.sub(r\"zealand\", \"Zealand\", text)\n",
    "    text = re.sub(r\"norway\", \"Norway\", text)\n",
    "    text = re.sub(r\"india\", \"India\", text)\n",
    "    text = re.sub(r\"pakistan\", \"Pakistan\", text)\n",
    "    text = re.sub(r\"britain\", \"Britain\", text)\n",
    "    text = re.sub(r\"switzerland\", \"Switzerland\", text)\n",
    "    text = re.sub(r\"china\", \"China\", text)\n",
    "    text = re.sub(r\"chinese\", \"Chinese\", text) \n",
    "    text = re.sub(r\"imrovement\", \"improvement\", text)\n",
    "    text = re.sub(r\"intially\", \"initially\", text)\n",
    "    text = re.sub(r\"quora\", \"Quora\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)  \n",
    "    text = re.sub(r\"demonitization\", \"demonetization\", text) \n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvotes \", \" up votes \", text)\n",
    "    text = re.sub(r\" iphone \", \" phone \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text) \n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"gps\", \"GPS\", text)\n",
    "    text = re.sub(r\"gst\", \"GST\", text)\n",
    "    text = re.sub(r\"programing\", \"programming\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"dna\", \"DNA\", text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_questions(question_list, questions, question_list_name, dataframe):\n",
    "    '''transform questions and display progress'''\n",
    "    for question in questions:\n",
    "        question_list.append(text_to_wordlist(question))\n",
    "        if len(question_list) % 100000 == 0:\n",
    "            progress = len(question_list)/len(dataframe) * 100\n",
    "            print(\"{} is {}% complete.\".format(question_list_name, round(progress, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_question1 is 24.7% complete.\n",
      "train_question1 is 49.5% complete.\n",
      "train_question1 is 74.2% complete.\n",
      "train_question1 is 98.9% complete.\n"
     ]
    }
   ],
   "source": [
    "train_question1 = []\n",
    "process_questions(train_question1, train.question1, 'train_question1', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_question2 is 24.7% complete.\n",
      "train_question2 is 49.5% complete.\n",
      "train_question2 is 74.2% complete.\n",
      "train_question2 is 98.9% complete.\n"
     ]
    }
   ],
   "source": [
    "train_question2 = []\n",
    "process_questions(train_question2, train.question2, 'train_question2', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_question1 is 4.3% complete.\n",
      "test_question1 is 8.5% complete.\n",
      "test_question1 is 12.8% complete.\n",
      "test_question1 is 17.1% complete.\n",
      "test_question1 is 21.3% complete.\n",
      "test_question1 is 25.6% complete.\n",
      "test_question1 is 29.8% complete.\n",
      "test_question1 is 34.1% complete.\n",
      "test_question1 is 38.4% complete.\n",
      "test_question1 is 42.6% complete.\n",
      "test_question1 is 46.9% complete.\n",
      "test_question1 is 51.2% complete.\n",
      "test_question1 is 55.4% complete.\n",
      "test_question1 is 59.7% complete.\n",
      "test_question1 is 63.9% complete.\n",
      "test_question1 is 68.2% complete.\n",
      "test_question1 is 72.5% complete.\n",
      "test_question1 is 76.7% complete.\n",
      "test_question1 is 81.0% complete.\n",
      "test_question1 is 85.3% complete.\n",
      "test_question1 is 89.5% complete.\n",
      "test_question1 is 93.8% complete.\n",
      "test_question1 is 98.0% complete.\n"
     ]
    }
   ],
   "source": [
    "test_question1 = []\n",
    "process_questions(test_question1, test.question1, 'test_question1', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_question2 is 4.3% complete.\n",
      "test_question2 is 8.5% complete.\n",
      "test_question2 is 12.8% complete.\n",
      "test_question2 is 17.1% complete.\n",
      "test_question2 is 21.3% complete.\n",
      "test_question2 is 25.6% complete.\n",
      "test_question2 is 29.8% complete.\n",
      "test_question2 is 34.1% complete.\n",
      "test_question2 is 38.4% complete.\n",
      "test_question2 is 42.6% complete.\n",
      "test_question2 is 46.9% complete.\n",
      "test_question2 is 51.2% complete.\n",
      "test_question2 is 55.4% complete.\n",
      "test_question2 is 59.7% complete.\n",
      "test_question2 is 63.9% complete.\n",
      "test_question2 is 68.2% complete.\n",
      "test_question2 is 72.5% complete.\n",
      "test_question2 is 76.7% complete.\n",
      "test_question2 is 81.0% complete.\n",
      "test_question2 is 85.3% complete.\n",
      "test_question2 is 89.5% complete.\n",
      "test_question2 is 93.8% complete.\n",
      "test_question2 is 98.0% complete.\n"
     ]
    }
   ],
   "source": [
    "test_question2 = []\n",
    "process_questions(test_question2, test.question2, 'test_question2', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the step by step guide to invest in share market in India \n",
      "what is the step by step guide to invest in share market \n",
      "\n",
      "what is the story of kohinoor koh - i - noor diamond \n",
      "what would happen if the Indian government stole the kohinoor koh - i - noor diamond back \n",
      "\n",
      "how can i increase the speed of my internet connection while using a vpn \n",
      "how can internet speed be increased by hacking through dns \n",
      "\n",
      "why am i mentally very lonely how can i solve it \n",
      "find the remainder when math 23 ^ 24 math is divided by 24 23 \n",
      "\n",
      "which one dissolve in water quickly sugar salt methane and carbon di oxide \n",
      "which fish would survive in salt water \n",
      "\n",
      "astrology i am a capricorn sun cap moon and cap rising what does that say about me \n",
      "i am a triple capricorn sun moon and ascendant in capricorn what does this say about me \n",
      "\n",
      "should i buy tiago \n",
      "what keeps childern active and far from phone and video games \n",
      "\n",
      "how can i be a good geologist \n",
      "what should i do to be a great geologist \n",
      "\n",
      "when do you use instead of \n",
      "when do you use instead of and \n",
      "\n",
      "motorola company can i hack my charter motorolla dcx3400 \n",
      "how do i hack motorola dcx3400 for free internet \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview some transformed pairs of questions\n",
    "i = 0\n",
    "for i in range(i,i+10):\n",
    "    print(train_question1[i])\n",
    "    print(train_question2[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_question1 is complete.\n",
      "train_question2 is complete\n",
      "test_question1 is complete.\n",
      "test_question2 is complete\n",
      "Total number of unique tokens: 4783127\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique tokens in the questions\n",
    "token_count = defaultdict(int)\n",
    "\n",
    "for question in train_question1:\n",
    "    token_count[question] += 1\n",
    "print(\"train_question1 is complete.\")\n",
    "    \n",
    "for question in train_question2:\n",
    "    token_count[question] += 1\n",
    "print(\"train_question2 is complete\")\n",
    "\n",
    "for question in test_question1:\n",
    "    token_count[question] += 1\n",
    "print(\"test_question1 is complete.\")\n",
    "\n",
    "for question in test_question2:\n",
    "    token_count[question] += 1\n",
    "print(\"test_question2 is complete\")\n",
    "\n",
    "print(\"Total number of unique tokens:\", len(token_count)) #4,780,591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the length of questions\n",
    "lengths = []\n",
    "for question in train_question1:\n",
    "    lengths.append(len(question.split()))\n",
    "\n",
    "for question in train_question2:\n",
    "    lengths.append(len(question.split()))\n",
    "\n",
    "# Create a dataframe so that the values can be inspected\n",
    "lengths = pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    808580.000000\n",
       "mean         11.259242\n",
       "std           6.077335\n",
       "min           0.000000\n",
       "25%           7.000000\n",
       "50%          10.000000\n",
       "75%          13.000000\n",
       "max         244.000000\n",
       "Name: counts, dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0\n",
      "35.0\n",
      "37.0\n",
      "53.0\n"
     ]
    }
   ],
   "source": [
    "print(np.percentile(lengths.counts, 99.0))\n",
    "print(np.percentile(lengths.counts, 99.4))\n",
    "print(np.percentile(lengths.counts, 99.5))\n",
    "print(np.percentile(lengths.counts, 99.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting is complete.\n",
      "train_question1 is complete.\n",
      "train_question2 is complete\n"
     ]
    }
   ],
   "source": [
    "# tokenize the 200,000 most common words for all of the questions\n",
    "num_words = 200000\n",
    "\n",
    "all_questions = train_question1 + train_question2 + test_question1 + test_question2\n",
    "tokenizer = Tokenizer(num_words = num_words)\n",
    "tokenizer.fit_on_texts(all_questions)\n",
    "print(\"Fitting is complete.\")\n",
    "train_question1_word_sequences = tokenizer.texts_to_sequences(train_question1)\n",
    "print(\"train_question1 is complete.\")\n",
    "train_question2_word_sequences = tokenizer.texts_to_sequences(train_question2)\n",
    "print(\"train_question2 is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_question1 is complete.\n",
      "test_question2 is complete.\n"
     ]
    }
   ],
   "source": [
    "test_question1_word_sequences = tokenizer.texts_to_sequences(test_question1)\n",
    "print(\"test_question1 is complete.\")\n",
    "test_question2_word_sequences = tokenizer.texts_to_sequences(test_question2)\n",
    "print(\"test_question2 is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in index: 120588\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(\"Words in index: %d\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_q1 is complete.\n",
      "train_q2 is complete.\n"
     ]
    }
   ],
   "source": [
    "# Pad the questions so that they all have the same length.\n",
    "\n",
    "max_question_len = 36\n",
    "\n",
    "train_q1 = pad_sequences(train_question1_word_sequences, \n",
    "                              maxlen = max_question_len,\n",
    "                              padding = 'post',\n",
    "                              truncating = 'post')\n",
    "print(\"train_q1 is complete.\")\n",
    "\n",
    "train_q2 = pad_sequences(train_question2_word_sequences, \n",
    "                              maxlen = max_question_len,\n",
    "                              padding = 'post',\n",
    "                              truncating = 'post')\n",
    "print(\"train_q2 is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_q1 is complete.\n",
      "test_q2 is complete.\n"
     ]
    }
   ],
   "source": [
    "test_q1 = pad_sequences(test_question1_word_sequences, \n",
    "                             maxlen = max_question_len,\n",
    "                             padding = 'post',\n",
    "                             truncating = 'post')\n",
    "print(\"test_q1 is complete.\")\n",
    "\n",
    "test_q2 = pad_sequences(test_question2_word_sequences, \n",
    "                             maxlen = max_question_len,\n",
    "                             padding = 'post',\n",
    "                             truncating = 'post')\n",
    "print(\"test_q2 is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = train.is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 151250\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe to use pretrained vectors\n",
    "# From this link: https://nlp.stanford.edu/projects/glove/\n",
    "embeddings_index = {}\n",
    "with open('glove.840B.300d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index)) #151,250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 75386\n"
     ]
    }
   ],
   "source": [
    "# Need to use 300 for embedding dimensions to match GloVe's vectors.\n",
    "embedding_dim = 300\n",
    "\n",
    "nb_words = len(word_index)\n",
    "word_embedding_matrix = np.zeros((nb_words + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0)) #75,334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:90: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:102: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:116: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "units = 128 # Number of nodes in the Dense layers\n",
    "dropout = 0.25 # Percentage of nodes to drop\n",
    "nb_filter = 32 # Number of filters to use in Convolution1D\n",
    "filter_length = 3 # Length of filter for Convolution1D\n",
    "# Initialize weights and biases for the Dense layers\n",
    "weights = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=2)\n",
    "bias = bias_initializer='zeros'\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(nb_words + 1,\n",
    "                     embedding_dim,\n",
    "                     weights = [word_embedding_matrix],\n",
    "                     input_length = max_question_len,\n",
    "                     trainable = False))\n",
    "\n",
    "model1.add(Convolution1D(filters = nb_filter, \n",
    "                         kernel_size = filter_length, \n",
    "                         padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(dropout))\n",
    "\n",
    "model1.add(Convolution1D(filters = nb_filter, \n",
    "                         kernel_size = filter_length, \n",
    "                         padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(dropout))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(nb_words + 1,\n",
    "                     embedding_dim,\n",
    "                     weights = [word_embedding_matrix],\n",
    "                     input_length = max_question_len,\n",
    "                     trainable = False))\n",
    "\n",
    "model2.add(Convolution1D(filters = nb_filter, \n",
    "                         kernel_size = filter_length, \n",
    "                         padding = 'same'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(dropout))\n",
    "\n",
    "model2.add(Convolution1D(filters = nb_filter, \n",
    "                         kernel_size = filter_length, \n",
    "                         padding = 'same'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(dropout))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(nb_words + 1,\n",
    "                     embedding_dim,\n",
    "                     weights = [word_embedding_matrix],\n",
    "                     input_length = max_question_len,\n",
    "                     trainable = False))\n",
    "model3.add(TimeDistributed(Dense(embedding_dim)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(dropout))\n",
    "model3.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim, )))\n",
    "\n",
    "\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(nb_words + 1,\n",
    "                     embedding_dim,\n",
    "                     weights = [word_embedding_matrix],\n",
    "                     input_length = max_question_len,\n",
    "                     trainable = False))\n",
    "\n",
    "model4.add(TimeDistributed(Dense(embedding_dim)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(dropout))\n",
    "model4.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim, )))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "modela = Sequential()\n",
    "modela.add(Merge([model1, model2], mode='concat'))\n",
    "modela.add(Dense(units*2, kernel_initializer=weights, bias_initializer=bias))\n",
    "modela.add(BatchNormalization())\n",
    "modela.add(Activation('relu'))\n",
    "modela.add(Dropout(dropout))\n",
    "\n",
    "modela.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "modela.add(BatchNormalization())\n",
    "modela.add(Activation('relu'))\n",
    "modela.add(Dropout(dropout))\n",
    "\n",
    "modelb = Sequential()\n",
    "modelb.add(Merge([model3, model4], mode='concat'))\n",
    "modelb.add(Dense(units*2, kernel_initializer=weights, bias_initializer=bias))\n",
    "modelb.add(BatchNormalization())\n",
    "modelb.add(Activation('relu'))\n",
    "modelb.add(Dropout(dropout))\n",
    "\n",
    "modelb.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "modelb.add(BatchNormalization())\n",
    "modelb.add(Activation('relu'))\n",
    "modelb.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([modela, modelb], mode='concat'))\n",
    "model.add(Dense(units*2, kernel_initializer=weights, bias_initializer=bias))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(1, kernel_initializer=weights, bias_initializer=bias))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 343646 samples, validate on 60644 samples\n",
      "Epoch 1/100\n",
      "343646/343646 [==============================] - 1805s - loss: 0.5381 - acc: 0.7265 - val_loss: 0.4960 - val_acc: 0.7489\n",
      "Epoch 2/100\n",
      "343646/343646 [==============================] - 1639s - loss: 0.4645 - acc: 0.7724 - val_loss: 0.4445 - val_acc: 0.7851\n",
      "Epoch 3/100\n",
      "343646/343646 [==============================] - 1580s - loss: 0.4351 - acc: 0.7889 - val_loss: 0.4259 - val_acc: 0.7931\n",
      "Epoch 4/100\n",
      "343646/343646 [==============================] - 1582s - loss: 0.4147 - acc: 0.8007 - val_loss: 0.4236 - val_acc: 0.7914\n",
      "Epoch 5/100\n",
      "343646/343646 [==============================] - 1589s - loss: 0.4001 - acc: 0.8102 - val_loss: 0.4056 - val_acc: 0.8048\n",
      "Epoch 6/100\n",
      "343646/343646 [==============================] - 1593s - loss: 0.3864 - acc: 0.8177 - val_loss: 0.3878 - val_acc: 0.8143\n",
      "Epoch 7/100\n",
      "343646/343646 [==============================] - 1600s - loss: 0.3751 - acc: 0.8247 - val_loss: 0.4020 - val_acc: 0.8047\n",
      "Epoch 8/100\n",
      "343646/343646 [==============================] - 1598s - loss: 0.3639 - acc: 0.8311 - val_loss: 0.3936 - val_acc: 0.8089\n",
      "Epoch 9/100\n",
      "343646/343646 [==============================] - 1596s - loss: 0.3541 - acc: 0.8362 - val_loss: 0.3915 - val_acc: 0.8128\n",
      "Epoch 10/100\n",
      "343646/343646 [==============================] - 1597s - loss: 0.3471 - acc: 0.8401 - val_loss: 0.3769 - val_acc: 0.8224\n",
      "Epoch 11/100\n",
      "343646/343646 [==============================] - 1596s - loss: 0.3389 - acc: 0.8457 - val_loss: 0.3788 - val_acc: 0.8205\n",
      "Epoch 12/100\n",
      "343646/343646 [==============================] - 1596s - loss: 0.3315 - acc: 0.8494 - val_loss: 0.3811 - val_acc: 0.8175\n",
      "Epoch 13/100\n",
      "343646/343646 [==============================] - 1598s - loss: 0.3249 - acc: 0.8528 - val_loss: 0.3734 - val_acc: 0.8216\n",
      "Epoch 14/100\n",
      "343646/343646 [==============================] - 1598s - loss: 0.3193 - acc: 0.8554 - val_loss: 0.3760 - val_acc: 0.8219\n",
      "Epoch 15/100\n",
      "343646/343646 [==============================] - 1598s - loss: 0.3133 - acc: 0.8594 - val_loss: 0.3771 - val_acc: 0.8199\n",
      "Epoch 16/100\n",
      "343646/343646 [==============================] - 1599s - loss: 0.3089 - acc: 0.8610 - val_loss: 0.3773 - val_acc: 0.8201\n",
      "Epoch 17/100\n",
      "343646/343646 [==============================] - 1597s - loss: 0.3033 - acc: 0.8646 - val_loss: 0.3937 - val_acc: 0.8106\n",
      "Epoch 18/100\n",
      "343646/343646 [==============================] - 1597s - loss: 0.2992 - acc: 0.8661 - val_loss: 0.3822 - val_acc: 0.8167\n",
      "Epoch 19/100\n",
      "343646/343646 [==============================] - 1597s - loss: 0.2955 - acc: 0.8680 - val_loss: 0.3828 - val_acc: 0.8190\n",
      "Epoch 00018: early stopping\n",
      "Minutes elapsed: 509.609739\n"
     ]
    }
   ],
   "source": [
    "# save the best weights for predicting the test question pairs\n",
    "save_best_weights = 'question_pairs_weights.h5'\n",
    "\n",
    "t0 = time.time()\n",
    "callbacks = [ModelCheckpoint(save_best_weights, monitor='val_loss', save_best_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')]\n",
    "history = model.fit([train_q1, train_q2, train_q1, train_q2],\n",
    "                    y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    validation_split=0.15,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate the summary statistics\n",
    "summary_stats = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                              'train_acc': history.history['acc'],\n",
    "                              'valid_acc': history.history['val_acc'],\n",
    "                              'train_loss': history.history['loss'],\n",
    "                              'valid_loss': history.history['val_loss']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.726515</td>\n",
       "      <td>0.538137</td>\n",
       "      <td>0.748912</td>\n",
       "      <td>0.495959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.772367</td>\n",
       "      <td>0.464475</td>\n",
       "      <td>0.785140</td>\n",
       "      <td>0.444471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.788908</td>\n",
       "      <td>0.435145</td>\n",
       "      <td>0.793121</td>\n",
       "      <td>0.425925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.800658</td>\n",
       "      <td>0.414688</td>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.423571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.810215</td>\n",
       "      <td>0.400064</td>\n",
       "      <td>0.804795</td>\n",
       "      <td>0.405567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.817748</td>\n",
       "      <td>0.386420</td>\n",
       "      <td>0.814260</td>\n",
       "      <td>0.387757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.824686</td>\n",
       "      <td>0.375122</td>\n",
       "      <td>0.804713</td>\n",
       "      <td>0.402002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.831082</td>\n",
       "      <td>0.363883</td>\n",
       "      <td>0.808918</td>\n",
       "      <td>0.393636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.836221</td>\n",
       "      <td>0.354138</td>\n",
       "      <td>0.812776</td>\n",
       "      <td>0.391497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.840120</td>\n",
       "      <td>0.347141</td>\n",
       "      <td>0.822357</td>\n",
       "      <td>0.376932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.845728</td>\n",
       "      <td>0.338878</td>\n",
       "      <td>0.820460</td>\n",
       "      <td>0.378785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.849412</td>\n",
       "      <td>0.331472</td>\n",
       "      <td>0.817542</td>\n",
       "      <td>0.381079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.852753</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>0.821631</td>\n",
       "      <td>0.373406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.855372</td>\n",
       "      <td>0.319340</td>\n",
       "      <td>0.821895</td>\n",
       "      <td>0.376048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.859437</td>\n",
       "      <td>0.313291</td>\n",
       "      <td>0.819949</td>\n",
       "      <td>0.377115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.860964</td>\n",
       "      <td>0.308889</td>\n",
       "      <td>0.820098</td>\n",
       "      <td>0.377311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.864622</td>\n",
       "      <td>0.303282</td>\n",
       "      <td>0.810600</td>\n",
       "      <td>0.393699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.866092</td>\n",
       "      <td>0.299240</td>\n",
       "      <td>0.816668</td>\n",
       "      <td>0.382214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.867980</td>\n",
       "      <td>0.295480</td>\n",
       "      <td>0.819026</td>\n",
       "      <td>0.382761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_acc  train_loss  valid_acc  valid_loss\n",
       "0       1   0.726515    0.538137   0.748912    0.495959\n",
       "1       2   0.772367    0.464475   0.785140    0.444471\n",
       "2       3   0.788908    0.435145   0.793121    0.425925\n",
       "3       4   0.800658    0.414688   0.791373    0.423571\n",
       "4       5   0.810215    0.400064   0.804795    0.405567\n",
       "5       6   0.817748    0.386420   0.814260    0.387757\n",
       "6       7   0.824686    0.375122   0.804713    0.402002\n",
       "7       8   0.831082    0.363883   0.808918    0.393636\n",
       "8       9   0.836221    0.354138   0.812776    0.391497\n",
       "9      10   0.840120    0.347141   0.822357    0.376932\n",
       "10     11   0.845728    0.338878   0.820460    0.378785\n",
       "11     12   0.849412    0.331472   0.817542    0.381079\n",
       "12     13   0.852753    0.324900   0.821631    0.373406\n",
       "13     14   0.855372    0.319340   0.821895    0.376048\n",
       "14     15   0.859437    0.313291   0.819949    0.377115\n",
       "15     16   0.860964    0.308889   0.820098    0.377311\n",
       "16     17   0.864622    0.303282   0.810600    0.393699\n",
       "17     18   0.866092    0.299240   0.816668    0.382214\n",
       "18     19   0.867980    0.295480   0.819026    0.382761"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x154a87630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(summary_stats.train_loss) # blue\n",
    "plt.plot(summary_stats.valid_loss) # green\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum loss at epoch 13 = 0.3734\n"
     ]
    }
   ],
   "source": [
    "# Find the minimum validation loss during the training\n",
    "min_loss, idx = min((loss, idx) for (idx, loss) in enumerate(history.history['val_loss']))\n",
    "print('Minimum loss at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(min_loss))\n",
    "min_loss = round(min_loss, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345792/2345796 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best weights\n",
    "model.load_weights(save_best_weights)\n",
    "predictions = model.predict([test_q1, test_q2, test_q1, test_q2], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create submission\n",
    "submission = pd.DataFrame(predictions, columns=['is_duplicate'])\n",
    "submission.insert(0, 'test_id', test.test_id)\n",
    "file_name = 'submission_{}.csv'.format(min_loss)\n",
    "submission.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.054217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.093852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.817997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.496896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.019695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.902416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.959842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.918632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.205630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.054217\n",
       "1        1      0.093852\n",
       "2        2      0.817997\n",
       "3        3      0.087583\n",
       "4        4      0.496896\n",
       "5        5      0.019695\n",
       "6        6      0.902416\n",
       "7        7      0.959842\n",
       "8        8      0.918632\n",
       "9        9      0.205630"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am still trying to improve this model, and for the most part, it is going rather well. Currently, I am ranked in the top 14% of the competition. A few different strategies that I still want to test out:\n",
    "- Improving how I clean the text. I have yet to find a fast and accurate function that I can import to do this.\n",
    "- Initializing the weights and biases differently. I have read that using truncated normal can be effective, but I want to try using different standard deviations.\n",
    "- Although I have already tried many different architectures, I will keep reading about this subject and see what useful information I can find and implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
